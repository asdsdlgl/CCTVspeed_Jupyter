{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import *\n",
    "from keras.utils import Sequence\n",
    "from keras.models import Model\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from vis.utils import utils\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "import cv2\n",
    "import keras.backend as K\n",
    "rn.seed(666)\n",
    "tf.set_random_seed(666)\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n",
    "\n",
    "\n",
    "def compare_two_layer(layer1, layer2, m):\n",
    "    idx1, idx2 = utils.find_layer_idx(m, layer1), utils.find_layer_idx(m, layer2)\n",
    "    model1 = Model(inputs=m.inputs, outputs=m.layers[idx1].output)\n",
    "    model2 = Model(inputs=m.inputs, outputs=m.layers[idx2].output)\n",
    "    maps1 = model1.predict([X1[0].reshape(1, 50, 72, 106, 1), X2[0].reshape(1, 50, 13, 13, 1),\n",
    "                            X3[0].reshape(1, 13, 13, 1), X4[0].reshape(1, 13, 13, 1)])\n",
    "    maps2 = model2.predict([X1[0].reshape(1, 50, 72, 106, 1), X2[0].reshape(1, 50, 13, 13, 1),\n",
    "                            X3[0].reshape(1, 13, 13, 1), X4[0].reshape(1, 13, 13, 1)])\n",
    "    width = maps1.shape[3] * 10 if maps1.shape[3] > 10 else maps1.shape[3] * 20\n",
    "    height = maps1.shape[2] * 10 if maps1.shape[3] > 10 else maps1.shape[2] * 20\n",
    "    print(maps1.shape)\n",
    "    print(np.array_equal(maps1, maps2))\n",
    "    # video = cv2.VideoWriter(\"fmaps/L1.mp4\", -1, 3, (width, height))\n",
    "    video = cv2.VideoWriter(\"fmaps/compare.mp4\", -1, 5, (width*2, height))\n",
    "    for _ in range(maps1.shape[1]):\n",
    "        map1 = maps1[0, _, :, :, 1]\n",
    "        map2 = maps2[0, _, :, :, 1]\n",
    "        im = np.hstack((map1, map2))\n",
    "        im = cv2.resize(im, (width*2, height), interpolation=cv2.INTER_NEAREST).astype(np.uint8)\n",
    "        video.write(im*30 + 80)\n",
    "        # cv2.imshow('final', np.where((255 - im) < 80, 255, im+80))\n",
    "        # cv2.imshow('final', Contrast_and_Brightness(10, 50, im))\n",
    "        # cv2.imshow('final', im*50+70)\n",
    "        # k = cv2.waitKey(60) & 0xff\n",
    "        # if k == 27:\n",
    "        #     break\n",
    "    cv2.destroyAllWindows()\n",
    "    video.release()\n",
    "\n",
    "\n",
    "def plot_all_maps(layer):\n",
    "    print(layer)\n",
    "    idx = utils.find_layer_idx(model, layer)\n",
    "    activation_model = Model(inputs=model.inputs, outputs=model.layers[idx].output)\n",
    "    feature_maps = activation_model.predict([X1[0].reshape(1, 50, 72, 106, 1), X2[0].reshape(1, 50, 13, 13, 1),\n",
    "                                             X3[0].reshape(1, 13, 13, 1), X4[0].reshape(1, 13, 13, 1)])\n",
    "    feature_maps = feature_maps.reshape((1, 50, 3, 5, 32))\n",
    "    print(feature_maps.shape)\n",
    "    width = feature_maps.shape[3] * 200\n",
    "    height = feature_maps.shape[2] * 400\n",
    "    # print(height)\n",
    "    # video = cv2.VideoWriter(\"fmaps/L1.mp4\", -1, 3, (width, height))\n",
    "    video = cv2.VideoWriter(\"fmaps/\" + layer + \"_all_maps.mp4\", -1, 3, (width, height))\n",
    "    id = 0\n",
    "    for _ in range(feature_maps.shape[1]):\n",
    "        # specify subplot and turn of axis\n",
    "        # ax = plt.subplot(h, w, ix)\n",
    "        # ax.set_xticks([])\n",
    "        # ax.set_yticks([])\n",
    "        # plot filter channel in grayscale\n",
    "        map = feature_maps[0, _, :, :, 0]\n",
    "        for y in range(1, 4, 1):\n",
    "            map = np.concatenate((map, feature_maps[0, _, :, :, y]), axis=1)\n",
    "        for x in range(1, 8, 1):\n",
    "            tmp = feature_maps[0, _, :, :, x*4]\n",
    "            for y in range(1, 4, 1):\n",
    "                tmp = np.concatenate((tmp, feature_maps[0, _, :, :, y+x*y]), axis=1)\n",
    "            map = np.concatenate((map, tmp), axis=0)\n",
    "        map = cv2.resize(map, (width, height), interpolation=cv2.INTER_NEAREST)\n",
    "        map = (map*5000 + 50).astype(np.uint8)\n",
    "        for i in range(1, 4):\n",
    "            cv2.line(map, ((width*i)//4, 0), ((width*i//4), height), (255, 255, 255), 2)\n",
    "        for i in range(1, 8):\n",
    "            cv2.line(map, (0, (height*i)//8), (width, (height*i)//8), (255, 255, 255), 2)\n",
    "        # cv2.imwrite(\"fmaps/dense/f%d.png\" % id, map)\n",
    "        # id += 1\n",
    "        video.write(map)\n",
    "        # cv2.imshow('final', np.where((255 - im) < 80, 255, im+80))\n",
    "        # cv2.imshow('final', Contrast_and_Brightness(10, 50, im))\n",
    "        # cv2.imshow('final', map)\n",
    "        # k = cv2.waitKey(60) & 0xff\n",
    "        # if k == 27:\n",
    "        #     break\n",
    "    cv2.destroyAllWindows()\n",
    "    video.release()\n",
    "\n",
    "\n",
    "def compare_all_maps(layer1, layer2, m):\n",
    "    idx1, idx2 = utils.find_layer_idx(m, layer1), utils.find_layer_idx(m, layer2)\n",
    "    model1 = Model(inputs=m.inputs, outputs=m.layers[idx1].output)\n",
    "    model2 = Model(inputs=m.inputs, outputs=m.layers[idx2].output)\n",
    "    maps1 = model1.predict([X1[0].reshape(1, 50, 72, 106, 1), X2[0].reshape(1, 50, 13, 13, 1),\n",
    "                            X3[0].reshape(1, 13, 13, 1), X4[0].reshape(1, 13, 13, 1)])\n",
    "    maps2 = model2.predict([X1[0].reshape(1, 50, 72, 106, 1), X2[0].reshape(1, 50, 13, 13, 1),\n",
    "                            X3[0].reshape(1, 13, 13, 1), X4[0].reshape(1, 13, 13, 1)])\n",
    "    id = 0\n",
    "    for _ in range(maps1.shape[1]):\n",
    "        # specify subplot and turn of axis\n",
    "        # ax = plt.subplot(h, w, ix)\n",
    "        # ax.set_xticks([])\n",
    "        # ax.set_yticks([])\n",
    "        # plot filter channel in grayscale\n",
    "        map1 = maps1[0, _, :, :, 0]\n",
    "        for y in range(1, 4, 1):\n",
    "            map1 = np.concatenate((map1, maps1[0, _, :, :, y]), axis=1)\n",
    "        for x in range(1, 8, 1):\n",
    "            tmp = maps1[0, _, :, :, x*4]\n",
    "            for y in range(1, 4, 1):\n",
    "                tmp = np.concatenate((tmp, maps1[0, _, :, :, y+x*y]), axis=1)\n",
    "            map1 = np.concatenate((map1, tmp), axis=0)\n",
    "\n",
    "        map2 = maps2[0, _, :, :, 0]\n",
    "        for y in range(1, 4, 1):\n",
    "            map2 = np.concatenate((map2, maps2[0, _, :, :, y]), axis=1)\n",
    "        for x in range(1, 8, 1):\n",
    "            tmp = maps2[0, _, :, :, x * 4]\n",
    "            for y in range(1, 4, 1):\n",
    "                tmp = np.concatenate((tmp, maps2[0, _, :, :, y + x * y]), axis=1)\n",
    "            map2 = np.concatenate((map2, tmp), axis=0)\n",
    "        print(\"f%d:\" % id, np.array_equal(map1, map2))\n",
    "        id += 1\n",
    "\n",
    "\n",
    "def plot_layers_map():\n",
    "    for layer in layers:\n",
    "        print(layer)\n",
    "        idx = utils.find_layer_idx(model, layer)\n",
    "        activation_model = Model(inputs=model.inputs, outputs=model.layers[idx].output)\n",
    "        feature_maps = activation_model.predict([X1[0].reshape(1, 50, 72, 106, 1), X2[0].reshape(1, 50, 13, 13, 1),\n",
    "                                                 X3[0].reshape(1, 13, 13, 1), X4[0].reshape(1, 13, 13, 1)])\n",
    "        feature_maps = feature_maps.reshape((1, 50, 3, 5, 32))\n",
    "        print(feature_maps.shape)\n",
    "        width = feature_maps.shape[3] * 10 if feature_maps.shape[3] > 10 else feature_maps.shape[3] * 60\n",
    "        height = feature_maps.shape[2] * 10 if feature_maps.shape[3] > 10 else feature_maps.shape[2] * 60\n",
    "        # print(height)\n",
    "        # video = cv2.VideoWriter(\"fmaps/L1.mp4\", -1, 3, (width, height))\n",
    "        video = cv2.VideoWriter(\"fmaps/\" + layer + \"_2.mp4\", -1, 3, (width, height))\n",
    "        id = 0\n",
    "        for _ in range(feature_maps.shape[1]):\n",
    "            # specify subplot and turn of axis\n",
    "            # ax = plt.subplot(h, w, ix)\n",
    "            # ax.set_xticks([])\n",
    "            # ax.set_yticks([])\n",
    "            # plot filter channel in grayscale\n",
    "            map = np.mean(feature_maps[0, _, :, :, :], axis=2)\n",
    "            im = cv2.resize(map, (width, height), interpolation=cv2.INTER_NEAREST)\n",
    "            # cv2.imwrite(\"fmaps/dense/f%d.png\" % id, (im*100 + 50).astype(np.uint8))\n",
    "            # id += 1\n",
    "            video.write((im*5000 + 60).astype(np.uint8))\n",
    "            # cv2.imshow('final', np.where((255 - im) < 80, 255, im+80))\n",
    "            # cv2.imshow('final', Contrast_and_Brightness(10, 50, im))\n",
    "            # cv2.imshow('final', im)\n",
    "            # k = cv2.waitKey(60) & 0xff\n",
    "            # if k == 27:\n",
    "            #     break\n",
    "        cv2.destroyAllWindows()\n",
    "        video.release()\n",
    "\n",
    "\n",
    "def output_heatmap(model, last_conv_layer, img):\n",
    "    \"\"\"Get the heatmap for image.\n",
    "\n",
    "    Args:\n",
    "           model: keras model.\n",
    "           last_conv_layer: name of last conv layer in the model.\n",
    "           img: processed input image.\n",
    "\n",
    "    Returns:\n",
    "           heatmap: heatmap.\n",
    "    \"\"\"\n",
    "    # predict the image class\n",
    "    preds = model.predict(img)\n",
    "    # find the class index\n",
    "    index = np.argmax(preds[0])\n",
    "    # This is the entry in the prediction vector\n",
    "    target_output = model.output[:, index]\n",
    "\n",
    "    # get the last conv layer\n",
    "    last_conv_layer = model.get_layer(last_conv_layer)\n",
    "\n",
    "    # compute the gradient of the output feature map with this target class\n",
    "    grads = K.gradients(target_output, last_conv_layer.output)[0]\n",
    "\n",
    "    # mean the gradient over a specific feature map channel\n",
    "    pooled_grads = K.mean(grads, axis=(0, 1, 2, 3))\n",
    "\n",
    "    # this function returns the output of last_conv_layer and grads\n",
    "    # given the input picture\n",
    "    iterate = K.function([model.input], [pooled_grads, last_conv_layer.output[0]])\n",
    "    pooled_grads_value, conv_layer_output_value = iterate([img])\n",
    "\n",
    "    # We multiply each channel in the feature map array\n",
    "    # by \"how important this channel is\" with regard to the target class\n",
    "\n",
    "    for i in range(conv_layer_output_value.shape[-1]):\n",
    "        conv_layer_output_value[:, :, :, i] *= pooled_grads_value[i]\n",
    "\n",
    "    # The channel-wise mean of the resulting feature map\n",
    "    # is our heatmap of class activation\n",
    "    heatmap = np.mean(conv_layer_output_value, axis=-1)\n",
    "    # heatmap = np.maximum(heatmap, 0)\n",
    "    # heatmap /= np.max(heatmap)\n",
    "    c = 0\n",
    "    for i in heatmap[10:21]:\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        # plt.imshow(i, clim=(0.0, 0.2))\n",
    "        plt.imshow(i)\n",
    "        plt.set_cmap('nipy_spectral')\n",
    "        plt.savefig('fmaps/heatmap/f%d.png' % c, bbox_inches='tight', transparent=\"True\", pad_inches=0)\n",
    "        c += 1\n",
    "\n",
    "\n",
    "def Contrast_and_Brightness(alpha, beta, img):\n",
    "    blank = np.zeros(img.shape, img.dtype)\n",
    "    # dst = alpha * img + beta * blank\n",
    "    dst = cv2.addWeighted(img, alpha, blank, 1-alpha, beta)\n",
    "    return dst\n",
    "\n",
    "\n",
    "vds = ['nfbVD-N5-S-21.063-M-PS', 'nfbVD-N5-S-23.910-M-PS', 'nfbVD-N5-N-25.310-M-PS']\n",
    "# vds = ['nfbVD-N5-S-23.910-M-PS', 'nfbVD-N5-N-25.310-M-PS']\n",
    "\n",
    "cctvs = ['nfbCCTV-N5-N-16.915-M', 'nfbCCTV-N5-N-18.308-M', 'nfbCCTV-N5-N-22.514-M', 'nfbCCTV-N5-N-25.309-M',\n",
    "         'nfbCCTV-N5-S-18.339-M', 'nfbCCTV-N5-S-19.7-M', 'nfbCCTV-N5-S-21.048-M', 'nfbCCTV-N5-S-23.896-M']\n",
    "# cctvs = ['nfbCCTV-N5-S-23.896-M', 'nfbCCTV-N5-N-25.309-M']\n",
    "test_day1 = datetime.strptime('20190606 1800', \"%Y%m%d %H%M\")\n",
    "test_day1_str = test_day1.strftime(\"%Y%m%d %H%M\")\n",
    "\n",
    "batch_size = 32\n",
    "frame_num = 50\n",
    "\n",
    "model = models.load_model('model.h5')\n",
    "cctv_Id = 'nfbCCTV-N5-N-16.915-M'\n",
    "vd_Id = 'nfbVD-N5-S-21.063-M-PS'\n",
    "print(cctv_Id)\n",
    "vdDir = 'D:/vd/' + vd_Id + '/vd_speed/'\n",
    "cctvDir = 'E:/wcs/cctv/' + cctv_Id + \"/\"\n",
    "filename = vdDir + 'vdspd_20190321_20190421_nonzero.csv'\n",
    "total_frames = cctvDir + \"frame_num.txt\"\n",
    "# vd_df = pd.read_csv(filename, infer_datetime_format=True, index_col=0)\n",
    "# vd_df.index = pd.to_datetime(vd_df.index)\n",
    "# vd_df = vd_df.shift(-1)\n",
    "# vd_df.loc[vd_df.index[len(vd_df)-1]] = 90\n",
    "# frame_df = pd.read_csv(total_frames, infer_datetime_format=True, index_col=0, header=None)\n",
    "# frame_df.index = pd.to_datetime(frame_df.index)\n",
    "\n",
    "X1 = []\n",
    "X2 = []\n",
    "X3 = []\n",
    "X4 = []\n",
    "\n",
    "x_1 = list(np.load(cctvDir + test_day1.strftime(\"%Y%m%d\") + \"_\" + test_day1.strftime(\"%H%M\") + '.npy')[:frame_num])\n",
    "x_2 = list(np.load(cctvDir + test_day1.strftime(\"%Y%m%d\") + \"_\" + test_day1.strftime(\"%H%M\") + '_timestamp.npy')[:frame_num])\n",
    "X3.append(x_2[len(x_2) - 1])\n",
    "X4.append(x_2[0])\n",
    "while len(x_1) < frame_num:\n",
    "    x_1.append(np.zeros_like(x_1[0]))\n",
    "    x_2.append(np.zeros_like(x_2[0]))\n",
    "X1.append(x_1[:frame_num])\n",
    "X2.append(x_2[:frame_num])\n",
    "X1 = np.array(X1)\n",
    "X2 = np.array(X2)\n",
    "X3 = np.array(X3)\n",
    "X4 = np.array(X4)\n",
    "print(\"Test length:\", len(X1))\n",
    "\n",
    "# testing_generator = DataGenerator(X_test, X_test_fnum, y_test, frame_num, False)\n",
    "# testPrdct = model.predict_generator(generator=testing_generator, verbose=1, steps=len(X_test) // batch_size,\n",
    "#                                     max_queue_size=200, workers=32)\n",
    "# testPrdct = np.squeeze(testPrdct)\n",
    "# mae = abs(y_test[:len(testPrdct)] - testPrdct).mean()\n",
    "# print(\"MAE:\", \"%.2f\" % mae)\n",
    "layer_outputs = [layer.output for layer in model.layers]\n",
    "activation_model = Model(inputs=model.input, outputs=layer_outputs)\n",
    "activation_model.summary()\n",
    "layers = ['time_distributed_13', 'time_distributed_14', 'time_distributed_15', 'time_distributed_16', 'time_distributed_17',\n",
    "          'time_distributed_18', 'reshape_3', 'conv3d_13', 'conv3d_14', 'conv3d_15', 'max_pooling3d_15']\n",
    "# layers = ['time_distributed_7', 'time_distributed_8', 'time_distributed_9', 'time_distributed_10', 'time_distributed_11',\n",
    "#           'time_distributed_12', 'reshape_2', 'conv3d_7', 'conv3d_8', 'conv3d_9', 'max_pooling3d_9']\n",
    "layers = ['conv3d_1''conv3d_7''time_distributed_3']\n",
    "output_heatmap(model, 'time_distributed_3', X1)\n",
    "# plot_layers_map()\n",
    "# compare_two_layer('time_distributed_12', 'reshape_2', model)\n",
    "# reshape_4, time_distributed_24\n",
    "# plot_all_maps('reshape_3')\n",
    "# compare_all_maps('time_distributed_18', 'reshape_3', model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
