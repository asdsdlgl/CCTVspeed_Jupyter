{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Import Package<br>\n",
    "以其中一支CCTV的模型來測試別支CCTV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import *\n",
    "from keras.utils import Sequence\n",
    "from keras.models import Model\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "config = tf.ConfigProto()                           # 此三行的目的是讓TensorFlow在運行過程中動態申請顯存，需要多少就申請多少\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Class Define<br>\n",
    "論文第10頁<br>\n",
    "參考 : 英文 https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly <br>\n",
    "      中文 https://blog.csdn.net/m0_37477175/article/details/79716312 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs_1, list_IDs_3, labels, fnum, peak, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.list_IDs_1 = list_IDs_1\n",
    "        self.list_IDs_3 = list_IDs_3\n",
    "        self.fnum = fnum\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "        self.peak = peak\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs_1) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp_1, X5, y = [self.list_IDs_1[k] for k in indexes],\\\n",
    "                                 [self.list_IDs_3[k] for k in indexes],\\\n",
    "                                 [self.labels[k] for k in indexes]\n",
    "        # Generate data\n",
    "        X1 = self.__data_generation(list_IDs_temp_1, indexes)\n",
    "        return X1, np.array(y, dtype=int)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs_1))\n",
    "        if self.shuffle == True:\n",
    "            np.random.seed(666)\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp_1, y_index):\n",
    "        'Generates data containing batch_size samples'\n",
    "        # Initialization\n",
    "        X1 = []\n",
    "        # Generate data\n",
    "        for ID, y_ID in zip(list_IDs_temp_1, y_index):\n",
    "            # Store sample\n",
    "            x_1 = list(np.load(ID.split(\" \")[0] + '.npy')) #(59,72,106,1)\n",
    "            tmp = []\n",
    "            for frame in x_1:                   #(72,106,1)\n",
    "                frame = frame[:, 9:]            #(72,97,1)\n",
    "                frame = np.concatenate((frame, np.zeros((72, 9, 1))), axis=1) #右側填0\n",
    "                tmp.append(frame)\n",
    "            x_1 = list(tmp)\n",
    "            if len(x_1) >= 120:\n",
    "                x_1 = x_1[70:120]\n",
    "            else:\n",
    "                x_1 = x_1[:frame_num]\n",
    "            while len(x_1) < self.fnum:\n",
    "                x_1.append(np.zeros_like(x_1[0]))\n",
    "            X1.append(x_1)\n",
    "            # Store class\n",
    "        X1 = np.array(X1)\n",
    "        return X1\n",
    "\n",
    "\n",
    "class FrameInterval:\n",
    "    def __init__(self):\n",
    "        self.train_df = pd.DataFrame(columns=['data'], dtype=str)\n",
    "        self.test_df = pd.DataFrame(columns=['data'], dtype=str)\n",
    "        self.val_df = pd.DataFrame(columns=['data'], dtype=str)\n",
    "\n",
    "    def add_train(self, data, datatime):\n",
    "        df = pd.DataFrame(columns=['data'], dtype=str)\n",
    "        df.loc[datatime] = [data]\n",
    "        self.train_df = self.train_df.append(df)\n",
    "        self.train_df.index = pd.to_datetime(self.train_df.index)\n",
    "\n",
    "    def add_test(self, data, datatime):\n",
    "        self.test_df.loc[datatime] = [data]\n",
    "        self.test_df.index = pd.to_datetime(self.test_df.index)\n",
    "\n",
    "    def add_val(self, data, datatime):\n",
    "        self.val_df.loc[datatime] = [data]\n",
    "        self.val_df.index = pd.to_datetime(self.val_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Basic setting<br>\n",
    "test_day1, dayLast: 測試時間<br>\n",
    "feature: 選擇真值(Spd_Max, Spd_Min, Spd_Avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vds = ['nfbVD-N5-N-16.900-M-PS', 'nfbVD-N5-N-18.313-M-PS', 'nfbVD-N5-N-22.510-M-PS', 'nfbVD-N5-N-25.310-M-PS',\n",
    "       'nfbVD-N5-S-18.312-M-PS', 'nfbVD-N5-S-19.677-M-PS', 'nfbVD-N5-S-21.063-M-PS', 'nfbVD-N5-S-23.910-M-PS']\n",
    "# vds = ['nfbVD-N5-S-18.312-M-PS', 'nfbVD-N5-S-19.677-M-PS', 'nfbVD-N5-S-21.063-M-PS', 'nfbVD-N5-S-23.910-M-PS']\n",
    "# vds = ['nfbVD-N5-S-21.063-M-PS', 'nfbVD-N5-S-23.910-M-PS', 'nfbVD-N5-N-25.310-M-PS']\n",
    "\n",
    "cctvs = ['nfbCCTV-N5-N-16.915-M', 'nfbCCTV-N5-N-18.308-M', 'nfbCCTV-N5-N-22.514-M', 'nfbCCTV-N5-N-25.309-M',\n",
    "         'nfbCCTV-N5-S-18.339-M', 'nfbCCTV-N5-S-19.7-M', 'nfbCCTV-N5-S-21.048-M', 'nfbCCTV-N5-S-23.896-M']\n",
    "# cctvs = ['nfbCCTV-N5-S-23.896-M', 'nfbCCTV-N5-N-25.309-M']\n",
    "# test_day1 = datetime.strptime('20190603 0000', \"%Y%m%d %H%M\")\n",
    "# test_day1_str = test_day1.strftime(\"%Y%m%d %H%M\")\n",
    "test_day1 = datetime.strptime('20190728 0600', \"%Y%m%d %H%M\")\n",
    "test_day1_str = test_day1.strftime(\"%Y%m%d %H%M\")\n",
    "dayLast = datetime.strptime('20190729 2359', \"%Y%m%d %H%M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Todo<br>\n",
    "model: 要訓練的神經網路模型<br>\n",
    "filename: 選擇vd真值的csv檔<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'Spd_Avg'\n",
    "batch_size = 32\n",
    "frame_num = 50\n",
    "\n",
    "for cctv_Id, vd_Id in zip(cctvs, vds):\n",
    "    print(cctv_Id)\n",
    "    vdDir = 'D:/vd/' + vd_Id + '/vd_speed/'\n",
    "    cctvDir = 'D:/wcs/cctv/' + cctv_Id + \"/\"\n",
    "    filename = vdDir + 'vdspd_20190517_20190609.csv'\n",
    "    total_frames = cctvDir + \"frame_num.txt\"\n",
    "    vd_df = pd.read_csv(filename, infer_datetime_format=True, index_col=0)\n",
    "    vd_df.index = pd.to_datetime(vd_df.index)\n",
    "    vd_df = vd_df.shift(-1)                                  #往上位移一位 因為資料取得有延遲\n",
    "    vd_df.loc[vd_df.index[len(vd_df)-1]] = 90                #將位移完後的nan填補90\n",
    "    frame_df = pd.read_csv(total_frames, infer_datetime_format=True, index_col=0, header=None)\n",
    "    frame_df.index = pd.to_datetime(frame_df.index)          #必須要用to_datetime 因為loc才能找到 從2019/07/29 ---> 2019-07-29\n",
    "    total_test_index = []\n",
    "    FrameList = []\n",
    "    with open(cctvDir + \"frame_interval.txt\") as f:\n",
    "        content = f.readlines()                              #['26\\n','9\\n'.....]\n",
    "    frame_interval = np.array([x.strip() for x in content], dtype=int)       # [ 26 , 9 , .....]\n",
    "    for i in range(len(content)):\n",
    "        FrameList.append(FrameInterval())\n",
    "    day = test_day1\n",
    "    while day <= dayLast:\n",
    "        # print(day)\n",
    "        if not os.path.exists(cctvDir + day.strftime(\"%Y%m%d\") + \"_\" + day.strftime(\"%H%M\") + \".npy\") \\\n",
    "                or day not in vd_df.index:\n",
    "            day += timedelta(minutes=1)\n",
    "            continue\n",
    "        FrameList[int(frame_df.loc[day]) // 10] \\\n",
    "            .add_test(cctvDir + day.strftime(\"%Y%m%d\") + \"_\" + day.strftime(\"%H%M\") + \" 0\", day)\n",
    "        total_test_index.append(day)\n",
    "        day += timedelta(minutes=1)\n",
    "\n",
    "    total_test = []\n",
    "    ModelTest_1, ModelTest_2 = [4, 5], [18, 19]\n",
    "    test = [ModelTest_1, ModelTest_2]\n",
    "    for peaks in range(2):\n",
    "        model = models.load_model('models/peak_%d/model.h5' % (peaks+1))\n",
    "        frame_num = 50\n",
    "        X_test = []\n",
    "        y_test_index = []\n",
    "        for t in test[peaks]:\n",
    "            X_test += FrameList[t].test_df['data'].tolist()\n",
    "            y_test_index += FrameList[t].test_df.index\n",
    "        X_test_fnum = frame_df.loc[y_test_index]\n",
    "        y_test = vd_df.loc[y_test_index, feature].values\n",
    "        X_test = np.array(X_test)\n",
    "        X_test_fnum = np.array(X_test_fnum)\n",
    "        y_test = np.array(y_test)\n",
    "        testing_generator = DataGenerator(X_test, X_test_fnum, y_test, frame_num, dir, False)\n",
    "        testPrdct = model.predict_generator(generator=testing_generator, verbose=0,\n",
    "                                            steps=len(X_test) // batch_size)\n",
    "        testPrdct = np.squeeze(testPrdct)\n",
    "        mae = abs(y_test[:len(testPrdct)] - testPrdct).mean()\n",
    "        # print(\"Peak\"+repr(peaks+1)+\" mae:\", \"%.2f\" % mae)\n",
    "        total_test += test[peaks]\n",
    "        index = 0\n",
    "        for t in test[peaks]:\n",
    "            temp = testPrdct[index:index + len(FrameList[t].test_df)].tolist()\n",
    "            while len(temp) < len(FrameList[t].test_df):\n",
    "                temp.append(temp[-1])\n",
    "            index += len(FrameList[t].test_df)\n",
    "            FrameList[t].test_df.insert(loc=0, column='predict', value=temp)\n",
    "    predict_df = pd.DataFrame(columns=['value'])\n",
    "    for i in total_test_index:\n",
    "        for j in total_test:\n",
    "            if i in FrameList[j].test_df.index:\n",
    "                predict_df.loc[i] = [FrameList[j].test_df.loc[i]['predict']]\n",
    "    df = pd.DataFrame(index=total_test_index)\n",
    "    predict_all = np.array(predict_df.loc[total_test_index, 'value'].values)\n",
    "    vd_all = np.array(vd_df.loc[total_test_index, feature].values)\n",
    "    df.insert(loc=0, column='target', value=vd_all)\n",
    "    df.insert(loc=0, column='predict', value=predict_df)\n",
    "    df = df.replace(r'\\s+', np.nan, regex=True).fillna(method='ffill')\n",
    "    df = df.replace(r'\\s+', np.nan, regex=True).fillna(method='bfill')\n",
    "    y = np.array(df['target'].values)\n",
    "    p = np.array(df['predict'].values)\n",
    "    mae = abs(y - p).mean()\n",
    "    std = abs(y - p).std()\n",
    "    # print(\"Total Std: %.2f\" % std)\n",
    "    print(\"Total MAE: %.2f\\n\" % mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
